{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXInxdYngU4/0604jhtqPJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"28uc6H4ZXiWi","executionInfo":{"status":"ok","timestamp":1733948269057,"user_tz":-330,"elapsed":31790,"user":{"displayName":"Yuvraj G","userId":"06843858227456057452"}},"outputId":"2b1775bb-f636-4fc8-a702-50a05195b520"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from xgboost import XGBClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","class BaseModel:\n","    def __init__(self):\n","        self.model = None\n","        self.scaler = StandardScaler()\n","        self.label_encoders = {}\n","\n","    def load(self, train_filepath, test_filepath):\n","        self.train_data = pd.read_excel(train_filepath)\n","        self.test_data = pd.read_excel(test_filepath)\n","        print(\"Training and testing data loaded successfully.\")\n","\n","    def preprocess(self):\n","        def process_data(data):\n","            # Feature engineering for transaction_date\n","            data['transaction_date'] = pd.to_datetime(data['transaction_date'])\n","            data['transaction_year'] = data['transaction_date'].dt.year\n","            data['transaction_month'] = data['transaction_date'].dt.month\n","\n","            # Drop unnecessary columns\n","            data = data.drop(['customer_id', 'transaction_date'], axis=1)\n","\n","            # Encode categorical variables\n","            categorical_cols = ['sub_grade', 'term', 'home_ownership', 'purpose', 'application_type', 'verification_status']\n","            for col in categorical_cols:\n","                if col not in self.label_encoders:\n","                    le = LabelEncoder()\n","                    data[col] = le.fit_transform(data[col])\n","                    self.label_encoders[col] = le\n","                else:\n","                    data[col] = self.label_encoders[col].transform(data[col])\n","\n","            # Scale numerical features\n","            numerical_cols = ['cibil_score', 'total_no_of_acc', 'annual_inc', 'int_rate',\n","                              'loan_amnt', 'installment', 'account_bal', 'emp_length', 'transaction_year', 'transaction_month']\n","            data[numerical_cols] = self.scaler.fit_transform(data[numerical_cols])\n","\n","            return data\n","\n","        self.train_data = process_data(self.train_data)\n","        self.test_data = process_data(self.test_data)\n","        print(\"Data preprocessing completed.\")\n","\n","    def split_data(self):\n","        X_train = self.train_data.drop('loan_status', axis=1)\n","        y_train = self.train_data['loan_status']\n","        X_test = self.test_data.drop('loan_status', axis=1)\n","        y_test = self.test_data['loan_status']\n","        return X_train, X_test, y_train, y_test\n","\n","    def train(self, X_train, y_train):\n","        raise NotImplementedError(\"Train method must be implemented by subclasses.\")\n","\n","    def test(self, X_test, y_test):\n","        y_pred = self.model.predict(X_test)\n","        report = classification_report(y_test, y_pred)\n","        cm = confusion_matrix(y_test, y_pred)\n","        print(\"Classification Report:\\n\", report)\n","        print(\"Confusion Matrix:\\n\", cm)\n","\n","    def predict(self, X):\n","        return self.model.predict(X)\n","\n","class XGBoostModel(BaseModel):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n","\n","    def train(self, X_train, y_train):\n","        self.model.fit(X_train, y_train)\n","        print(\"XGBoost model trained successfully.\")\n","\n","    def tune_hyperparameters_random(self, X_train, y_train):\n","        xgb_param_grid = {\n","            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n","            'n_estimators': [50, 100, 200, 300],\n","            'max_depth': [3, 5, 7, 9],\n","            'subsample': [0.6, 0.8, 0.9, 1.0],\n","            'colsample_bytree': [0.6, 0.7, 0.8, 1.0],\n","            'scale_pos_weight': [1, 2, 5]\n","        }\n","\n","        # Sample 20% of training data\n","        X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, test_size=0.8, random_state=42)\n","\n","        random_search = RandomizedSearchCV(\n","            estimator=self.model,\n","            param_distributions=xgb_param_grid,\n","            n_iter=20,  # Number of parameter settings sampled\n","            cv=5,\n","            scoring='accuracy',\n","            n_jobs=-1,\n","            random_state=42\n","        )\n","        random_search.fit(X_train_sample, y_train_sample)\n","        self.model = random_search.best_estimator_\n","        print(\"XGBoost model hyperparameter tuning with RandomizedSearchCV completed. Best parameters:\\n\", random_search.best_params_)\n","\n","# Example pipeline usage\n","if __name__ == \"__main__\":\n","    train_filepath = \"/content/train_data.xlsx\"\n","    test_filepath = \"/content/test_data.xlsx\"\n","\n","    # XGBoost pipeline without hyperparameter tuning\n","    xgb_default_model = XGBoostModel()\n","    xgb_default_model.load(train_filepath, test_filepath)\n","    xgb_default_model.preprocess()\n","    X_train, X_test, y_train, y_test = xgb_default_model.split_data()\n","    xgb_default_model.train(X_train, y_train)\n","    print(\"XGBoost Default Model:\")\n","    xgb_default_model.test(X_test, y_test)\n","\n","    # XGBoost pipeline with RandomizedSearchCV tuning\n","    xgb_random_model = XGBoostModel()\n","    xgb_random_model.load(train_filepath, test_filepath)\n","    xgb_random_model.preprocess()\n","    X_train, X_test, y_train, y_test = xgb_random_model.split_data()\n","    xgb_random_model.tune_hyperparameters_random(X_train, y_train)\n","    print(\"XGBoost RandomizedSearchCV Tuned Model:\")\n","    xgb_random_model.test(X_test, y_test)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p3wzYC5FY3lh","executionInfo":{"status":"ok","timestamp":1733956763854,"user_tz":-330,"elapsed":92281,"user":{"displayName":"Yuvraj G","userId":"06843858227456057452"}},"outputId":"d10e7881-af2a-4c98-ddf8-17701d00f129"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training and testing data loaded successfully.\n","Data preprocessing completed.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:38:13] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["XGBoost model trained successfully.\n","XGBoost Default Model:\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.68      0.17      0.27      3055\n","           1       0.67      0.95      0.79      5400\n","\n","    accuracy                           0.67      8455\n","   macro avg       0.67      0.56      0.53      8455\n","weighted avg       0.67      0.67      0.60      8455\n","\n","Confusion Matrix:\n"," [[ 507 2548]\n"," [ 244 5156]]\n","Training and testing data loaded successfully.\n","Data preprocessing completed.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:39:22] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["XGBoost model hyperparameter tuning with RandomizedSearchCV completed. Best parameters:\n"," {'subsample': 1.0, 'scale_pos_weight': 1, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n","XGBoost RandomizedSearchCV Tuned Model:\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.69      0.13      0.21      3055\n","           1       0.66      0.97      0.79      5400\n","\n","    accuracy                           0.66      8455\n","   macro avg       0.68      0.55      0.50      8455\n","weighted avg       0.67      0.66      0.58      8455\n","\n","Confusion Matrix:\n"," [[ 388 2667]\n"," [ 174 5226]]\n"]}]},{"cell_type":"markdown","source":["**XGBoost Tuned Model is the best model for loan default prediction as it ensures the majority of defaulters are predicted, achieving 97 percent recall. and Similar accuracy with Xgboost default model**\n","\n"],"metadata":{"id":"xpXZ23PI5YfS"}}]}